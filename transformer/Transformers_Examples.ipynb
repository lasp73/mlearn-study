{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en-w1OM0CYtL"
      },
      "source": [
        "# Exemplos com Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTwDyraeCgb6"
      },
      "source": [
        "## Dependências"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3utsXC8CXmF",
        "outputId": "4f446316-016b-4d56-a228-4787a02600bb"
      },
      "outputs": [],
      "source": [
        "%pip install transformers\n",
        "%pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD5_5FCEIykB"
      },
      "source": [
        "## Transformer encoder: BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiSJVVaEI31I",
        "outputId": "33947855-219c-40cc-ed40-58b4e8aec4ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "O \t O\n",
            "B-PUB \t Tribunal\n",
            "I-PUB \t de\n",
            "I-PUB \t Contas\n",
            "I-PUB \t da\n",
            "L-PUB \t União\n",
            "O \t é\n",
            "O \t localizado\n",
            "O \t em\n",
            "B-LOC \t Brasília\n",
            "O \t .\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertForTokenClassification, BertTokenizer, pipeline\n",
        "\n",
        "model = BertForTokenClassification.from_pretrained('monilouise/ner_news_portuguese')\n",
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased',\n",
        "                                          model_max_length=512,\n",
        "                                          do_lower_case=False)\n",
        "\n",
        "nlp = pipeline('ner', model=model, tokenizer=tokenizer)\n",
        "result = nlp(\"O Tribunal de Contas da União é localizado em Brasília.\", \n",
        "             ignore_labels=[])\n",
        "\n",
        "for token in result:\n",
        "  print(token['entity'], \"\\t\", token['word'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yPMODR0rmKe",
        "outputId": "cf2eedc4-53cd-4222-8617-99cda4104c84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'B-PUB', 'I-PUB', 'I-PUB', 'I-PUB', 'L-PUB', 'O', 'O', 'O', 'B-LOC']\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForTokenClassification\n",
        "import torch\n",
        "\n",
        "model = BertForTokenClassification.from_pretrained(\"monilouise/ner_news_portuguese\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "\n",
        "inputs = tokenizer(\n",
        "    \"O Tribunal de Contas da União é localizado em Brasília\", \n",
        "    add_special_tokens=False, \n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "\n",
        "predicted_token_class_ids = logits.argmax(-1)\n",
        "predicted_tokens_classes = [model.config.id2label[t.item()] for t in predicted_token_class_ids[0]]\n",
        "print(predicted_tokens_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnAtCbAu3DG_"
      },
      "source": [
        "## Decoder: GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtPiwsus5IuO",
        "outputId": "751f0bf5-0239-4552-e64f-3f17ac4cdebd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tell me where is Brazil and what is it?\n",
            "\n",
            "Brazil is a country that has been in the forefront of the development of the world's largest economy. It is a country that has been in\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", model_max_length=256)\n",
        "\n",
        "prompt = \"Tell me where is Brazil and what is it?\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(inputs.input_ids, max_length=40)\n",
        "\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31X3HmkwIuQj"
      },
      "source": [
        "## Decoder OPT-1.3b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rTRwkD_5Jce",
        "outputId": "c9f5818d-fe4c-486e-a015-f743eddeb346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tell me where is Brazil and what is it?\n",
            "It's a country in South America.\n",
            "I know, but what is it?\n",
            "It's a country in South America.\n",
            "I\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, OPTForCausalLM\n",
        "\n",
        "model = OPTForCausalLM.from_pretrained(\"facebook/opt-1.3b\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"facebook/opt-1.3b\")\n",
        "\n",
        "prompt = \"Tell me where is Brazil and what is it?\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate\n",
        "output = model.generate(inputs.input_ids, max_length=40)\n",
        "\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dq_qbrCCBkk6"
      },
      "source": [
        "## Transformer encoder-decoder: T5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qppw2dHOo53"
      },
      "source": [
        "O treinamento do T5 inclui Inglês => Francês\n",
        "\n",
        "Do Google Tradutor:\n",
        "\n",
        "**Inglês**: I'm a medical student because I want to help people.\n",
        "\n",
        "**Francês**: Je suis étudiant en médecine parce que je veux aider les gens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVYcooTFBdNK",
        "outputId": "6a53de26-4cbc-456d-b54c-00a599c7562f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Je suis étudiant en médecine parce que je veux aider les gens.\n"
          ]
        }
      ],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", model_max_length=256)\n",
        "\n",
        "input_ids = tokenizer(\"translate English to French: \\\n",
        "                       I'm a medical student because I want to help people.\", \n",
        "                      return_tensors=\"pt\").input_ids\n",
        "\n",
        "outputs = model.generate(input_ids)\n",
        "\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhyfeBFZI24U"
      },
      "source": [
        "## Testes com OPT-1.3b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuUusuIKI42E"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, OPTForCausalLM\n",
        "\n",
        "model = OPTForCausalLM.from_pretrained(\"facebook/opt-1.3b\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"facebook/opt-1.3b\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEPI-areLIke",
        "outputId": "87b2f1c0-8f71-4617-8b20-792c452e82ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How many legs does have a car?\n",
            "I think it's a car with legs.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"How many legs does have a car?\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate\n",
        "output = model.generate(inputs.input_ids, max_length=40)\n",
        "\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnyRYxSmJMdF",
        "outputId": "aef78314-3397-4551-992d-57b45dd82f71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Do you have a soul?\n",
            "I do not. I am a ghost. I am a ghost of a ghost. I am a ghost of a ghost. I am a ghost of a ghost\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Do you have a soul?\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate\n",
        "output = model.generate(inputs.input_ids, max_length=40)\n",
        "\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4EFs0nvJ0dw",
        "outputId": "714053d5-f9b5-4e42-f1f7-63ecdfd51d16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is a neural network?\n",
            "\n",
            "A neural network is a type of artificial intelligence that is trained to learn from data. It is a type of artificial intelligence that is trained to learn from data\n"
          ]
        }
      ],
      "source": [
        "prompt = \"What is a neural network?\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate\n",
        "output = model.generate(inputs.input_ids, max_length=40)\n",
        "\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Bh82908KF8p",
        "outputId": "d3041eb3-3665-4841-dd03-1f540c64aef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How many eyes have a house?\n",
            "\n",
            "The answer is: none.\n",
            "\n",
            "The eyes of a house are the windows.\n",
            "\n",
            "The windows of a house are the doors.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = \"How many eyes have a house?\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate\n",
        "output = model.generate(inputs.input_ids, max_length=40)\n",
        "\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FVxT2NSKXlz",
        "outputId": "9bb29e4a-d4fa-4e11-854b-05af0ae11785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Who is your father?\n",
            "I don't know.\n",
            "I don't know who he is.\n",
            "I don't know anything about him.\n",
            "I don't know anything about him.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Who is your father?\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate\n",
        "output = model.generate(inputs.input_ids, max_length=40)\n",
        "\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGDEMnGrLgAQ",
        "outputId": "7727db4d-25a5-4828-c9ce-1167a1f579b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the size of the Earth?\n",
            "\n",
            "The Earth is a sphere, about the size of a football field. It is the only planet in the solar system that is round.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = \"What is the size of the Earth?\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate\n",
        "output = model.generate(inputs.input_ids, max_length=40)\n",
        "\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "eTwDyraeCgb6",
        "JD5_5FCEIykB",
        "bnAtCbAu3DG_",
        "31X3HmkwIuQj",
        "dq_qbrCCBkk6"
      ],
      "name": "Transformers_Examples.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
